{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import packages\n",
    "import pandas as pd\n",
    "import missingno\n",
    "import numpy as np\n",
    "\n",
    "#from pathlib import Path\n",
    "import plotly.express as px\n",
    "\n",
    "from os import path\n",
    "\n",
    "import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the data year we want to examine\n",
    "ef_year = 2019\n",
    "\n",
    "# choose the units you want to use -either kgCO2/kWh or lbCO2/MWh\n",
    "units = 'lbCO2/MWh'\n",
    "\n",
    "# the base units are kg/kWh\n",
    "unit_conversion = 1\n",
    "if units == 'lbCO2/MWh':\n",
    "    unit_conversion = 1 / 0.453592 * 1000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the grid emission factor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the hourly emission factors\n",
    "##################################\n",
    "hourly_ef = pd.read_csv('../data/processed/emission_factors/emission_factors_monthhour.csv', index_col='datetime_local', parse_dates=True)\n",
    "\n",
    "# rename columns to remove EIA. prefix\n",
    "#hourly_ef.columns = [col.split('.')[-1] for col in hourly_ef.columns]\n",
    "# update list of regions\n",
    "ba_list = list(hourly_ef.columns)\n",
    "\n",
    "missingno.matrix(hourly_ef, labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate monthly and annual average EFs\n",
    "##########################################\n",
    "\n",
    "# calculate the monthly average\n",
    "mo_average = hourly_ef.copy()\n",
    "mo_average['month'] = mo_average.index.month\n",
    "mo_average = mo_average.groupby('month').mean().reset_index()\n",
    "#mo_average.columns = pd.MultiIndex.from_product([mo_average.columns, ['monthly']])\n",
    "\n",
    "#calculate the annual average\n",
    "yr_average = hourly_ef.copy()\n",
    "for col in yr_average.columns:\n",
    "    yr_average[col] = yr_average[col].mean()\n",
    "#yr_average.columns = pd.MultiIndex.from_product([yr_average.columns, ['annual']])\n",
    "\n",
    "# calculate the month-hour average\n",
    "mh_average = hourly_ef.copy()\n",
    "mh_average['month'] = mh_average.index.month\n",
    "mh_average['hour'] = mh_average.index.hour\n",
    "\n",
    "mh_average = mh_average.groupby(['month','hour']).mean().reset_index()\n",
    "\n",
    "# merge the averages\n",
    "ef = hourly_ef.copy()\n",
    "ef['month'] = ef.index.month\n",
    "ef['hour'] = ef.index.hour\n",
    "\n",
    "# merge month-hourly\n",
    "ef = ef.merge(mh_average, how='left', on=['month','hour'], suffixes=('_hourly','_monthhourly')).set_index(hourly_ef.index).drop(columns=['month','hour'])\n",
    "\n",
    "# merge the monthly\n",
    "ef['month'] = ef.index.month\n",
    "ef = ef.merge(mo_average.add_suffix('_monthly'), how='left', left_on='month', right_on='month_monthly').set_index(hourly_ef.index).drop(columns=['month', 'month_monthly'])\n",
    "\n",
    "# merge the annual data\n",
    "ef = ef.merge(yr_average.add_suffix('_annual'), how='left', left_index=True, right_index=True)\n",
    "\n",
    "# preserve the missing values of the hourly data across all resolutions\n",
    "for ba in ba_list:\n",
    "    for resolution in ['annual','monthly','monthhourly']:\n",
    "        ef.loc[ef[f'{ba}_hourly'].isna(), f'{ba}_{resolution}'] = np.NaN\n",
    "\n",
    "# split the columns into a multiindex by region and resolution\n",
    "split_columns = ef.columns.str.split('_', expand=True)\n",
    "ef.columns = split_columns\n",
    "split_columns = pd.MultiIndex.from_product([split_columns.levels[0], split_columns.levels[1]])\n",
    "ef = ef.reindex(columns=split_columns)\n",
    "\n",
    "# set the dtype to float32 to conserve memory\n",
    "ef = ef.astype('float32')\n",
    "\n",
    "ef.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the building demand data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list to hold the data\n",
    "demand = []\n",
    "\n",
    "# for each ba\n",
    "for ba in ba_list:\n",
    "    try:\n",
    "        ba_data = pd.read_csv(f'../data/processed/nrel_demand/{ba}.csv.zip', compression='zip', dtype='float16')\n",
    "        ba_data.columns = pd.MultiIndex.from_product([[ba], ba_data.columns], names=['location','building_type'])\n",
    "        # append the county data to the list\n",
    "        demand.append(ba_data)\n",
    "    except FileNotFoundError:\n",
    "        print(f'No demand data for {ba}')\n",
    "\n",
    "demand = pd.concat(demand, axis='columns')\n",
    "\n",
    "demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate inventories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_ef = ef.loc[:, (slice(None), 'hourly')].droplevel(1, axis=1).reset_index(drop=True)\n",
    "mh_ef = ef.loc[:, (slice(None), 'monthhourly')].droplevel(1, axis=1).reset_index(drop=True)\n",
    "monthly_ef = ef.loc[:, (slice(None), 'monthly')].droplevel(1, axis=1).reset_index(drop=True)\n",
    "annual_ef = ef.loc[:, (slice(None), 'annual')].droplevel(1, axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hourly inventory\n",
    "hourly_inventory = demand.multiply(hourly_ef, axis=1, level=0).sum()\n",
    "\n",
    "mh_inventory = demand.multiply(mh_ef, axis=1, level=0).sum()\n",
    "\n",
    "# monthly inventory\n",
    "monthly_inventory = demand.multiply(monthly_ef, axis=1, level=0).sum()\n",
    "\n",
    "# annual inventory\n",
    "annual_inventory = demand.multiply(annual_ef, axis=1, level=0).sum()\n",
    "\n",
    "combined_inventory = pd.DataFrame()\n",
    "combined_inventory['hourly'] = hourly_inventory\n",
    "combined_inventory['monthhourly'] = mh_inventory\n",
    "combined_inventory['monthly'] = monthly_inventory\n",
    "combined_inventory['annual'] = annual_inventory\n",
    "\n",
    "combined_inventory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Percentage Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate error metrics\n",
    "\n",
    "# calculate percent error\n",
    "percent_error = pd.DataFrame()\n",
    "percent_error['monthly'] = (monthly_inventory - hourly_inventory) / hourly_inventory\n",
    "percent_error['monthhourly'] = (mh_inventory - hourly_inventory) / hourly_inventory\n",
    "percent_error['annual'] = (annual_inventory - hourly_inventory) / hourly_inventory\n",
    "\n",
    "percent_error = percent_error.round(3)\n",
    "\n",
    "# create new columns for \n",
    "percent_error = percent_error.reset_index()\n",
    "percent_error['climate_zone'] = percent_error['building_type'].str.split('_', expand=True)[0]\n",
    "percent_error['building_category'] = percent_error['building_type'].str.split('_', expand=True)[1]\n",
    "percent_error['building_name'] = percent_error['building_type'].str.split('_', expand=True)[2]\n",
    "percent_error['building_id'] = percent_error['building_type'].str.split('_', expand=True)[3]\n",
    "\n",
    "# melt the data into long format\n",
    "percent_error = percent_error.drop(columns='building_type').melt(id_vars=['location','climate_zone', 'building_category','building_name','building_id'], var_name='resolution', value_name='error')\n",
    "# convert to percentage out of 100\n",
    "percent_error['error'] = percent_error['error'] * 100\n",
    "\n",
    "percent_error['building_sector'] = 'Commercial'\n",
    "residential_buildings = ['MobileHome', 'SingleFamily', 'MediumMultifamily',\n",
    "       'SmallMultifamily', 'LargeMultifamily']\n",
    "percent_error.loc[percent_error['building_category'].isin(residential_buildings), 'building_sector'] = 'Residential'\n",
    "\n",
    "# drop any rows with na values\n",
    "percent_error = percent_error.dropna(axis=0, how='any')\n",
    "\n",
    "# move the results for DOPD and CHPD to a separate dataframe\n",
    "percent_error_outliers = percent_error.copy()[percent_error['location'].isin(['DOPD','CHPD'])]\n",
    "percent_error = percent_error[~percent_error['location'].isin(['DOPD','CHPD'])]\n",
    "\n",
    "percent_error.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat for use in plotting\n",
    "percent_error_for_graph = percent_error.copy()[percent_error['resolution'] == 'annual'].drop(columns=['resolution'])\n",
    "\n",
    "# get some metadata that we will use for graph display\n",
    "descending_median_order = list(percent_error_for_graph.groupby(['location']).median().sort_values(by='error', ascending=False).index)\n",
    "descending_median_order_res = list(percent_error_for_graph[percent_error_for_graph['building_sector'] == 'Residential'].groupby(['location']).median().sort_values(by='error', ascending=False).index)\n",
    "descending_median_order_com = list(percent_error_for_graph[percent_error_for_graph['building_sector'] == 'Commercial'].groupby(['location']).median().sort_values(by='error', ascending=False).index)\n",
    "\n",
    "ba_name_dict = pd.read_csv('../data/manual/ba_names.csv', index_col='ba_code').to_dict()['ba_name']\n",
    "\n",
    "\n",
    "percent_error_for_graph.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## National Summary by BA and building Sector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse the order of the BA list\n",
    "descending_median_order.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_region_sector = px.box(percent_error_for_graph.replace({'location':ba_name_dict}), \n",
    "       y='location', \n",
    "       x='error', \n",
    "       category_orders={'location':[ba_name_dict[i] for i in descending_median_order]}, #sorted(ba_code_list)\n",
    "       template='plotly_white', \n",
    "       labels={'error':'%  by which annual accounting...','location':'Balancing Authority','building_sector':'Building Sector'}, \n",
    "       hover_data=['building_name','climate_zone'], \n",
    "       color='building_sector',\n",
    "       color_discrete_sequence=['blue', 'red'],\n",
    "       width=1000, \n",
    "       height=1200) \\\n",
    ".update_xaxes(zeroline=True, zerolinewidth=2, zerolinecolor='black', dtick=5, mirror='allticks', side='top') \\\n",
    ".update_yaxes(showgrid=True, ticks='outside', tickson='boundaries') \\\n",
    ".update_layout(boxgap=0.25, boxgroupgap=0, margin=dict(b=0, r=0), ) \\\n",
    ".update_layout(legend=dict(\n",
    "    yanchor=\"top\",\n",
    "    xanchor='center',\n",
    "    y=-0.01,\n",
    "    x=0.5,\n",
    "    orientation='h'), font_family=\"Helvetica\", font_size=14) \\\n",
    ".add_annotation(x=(percent_error_for_graph['error'].max()/2), y=1.035,\n",
    "                text=\"overestimates GHG\",\n",
    "                showarrow=False,\n",
    "                xref='x',\n",
    "                yref='paper') \\\n",
    ".add_annotation(x=(percent_error_for_graph['error'].min()/2), y=1.035,\n",
    "                text=\"underestimates GHG\",\n",
    "                showarrow=False,\n",
    "                xref='x',\n",
    "                yref='paper')\n",
    "error_by_region_sector.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_region_sector.write_image(\"../results/figures/figure_2/national_relative_bias_by_region_and_sector.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_by_region_sector.update_traces(line=dict(width=2)).write_image(\"../results/figures/figure_2/national_relative_bias_by_region_and_sector.svg\", scale=1.77165)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown by BA and Building type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean of the median absolute percent error for all building categories\n",
    "error_by_ba = percent_error.copy()[percent_error['resolution'] == 'annual']\n",
    "error_by_ba['error'] = abs(error_by_ba['error']) / 100\n",
    "error_by_ba = error_by_ba.groupby(['location','building_category']).median().reset_index().groupby(['location']).mean().reset_index()\n",
    "\n",
    "# get a list of all BAs in order of error\n",
    "descending_error_order = error_by_ba.sort_values(by='error', ascending=False)['location'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_bias_region_building = px.box(percent_error_for_graph, \n",
    "       x='building_category', \n",
    "       y='error', \n",
    "       facet_col='location', \n",
    "       facet_col_wrap=5, \n",
    "       facet_row_spacing=0.02, \n",
    "       color='building_category',\n",
    "       category_orders={'location':sorted(ba_list)}, #sorted(ba_list)\n",
    "       template='plotly_white', \n",
    "       labels={'error':'Bias (%)','building_category':'Building Type'}, \n",
    "       #hover_data=['building_name','climate_zone'], \n",
    "       width=1200, \n",
    "       height=1800,\n",
    "       boxmode='overlay') \\\n",
    ".update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='black', dtick=10) \\\n",
    ".update_xaxes(tickangle=45, showgrid=True, ticklabelposition='outside top') \\\n",
    ".for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1])) \\\n",
    ".update_layout(boxgap=0.01, font_family=\"Arial\", font_size=14)\n",
    "\n",
    "national_bias_region_building.write_image(\"../results/figures/SI/national_relative_bias_region_building.jpeg\")\n",
    "national_bias_region_building.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare accounting resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.histogram(percent_error, \n",
    "            x=\"error\", \n",
    "            color='resolution', \n",
    "            histnorm='percent', \n",
    "            category_orders={'resolution':['annual','monthly','monthhourly']}, \n",
    "            template='plotly_white', \n",
    "            title='Bias introduced through annual accounting<br>for all national GHG inventories', \n",
    "            nbins=100, \n",
    "            labels={'error':'% error'}).update_layout(barmode='overlay').update_traces(xbins=dict(start=-10.5, end=10.5,size=0.5), opacity=0.75).add_vline(x=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat the percent error data into a wid format\n",
    "percent_error_wide = percent_error.pivot(index=['location','building_sector','building_category','building_name','climate_zone','building_id'], columns='resolution', values='error').reset_index()\n",
    "percent_error_wide = percent_error_wide.sort_values(by='building_sector', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_error_wide['change'] = abs(percent_error_wide['monthly']) - abs(percent_error_wide['annual'])\n",
    "percent_error_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_error_wide[percent_error_wide['change'] >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_vs_monthly = px.scatter(percent_error_wide, \n",
    "           x=abs(percent_error_wide['annual']), \n",
    "           y=abs(percent_error_wide['monthly']), \n",
    "           labels={'x':'Absolute % Error (Annual)', 'y':'Absolute % Error (Monthly)','building_sector':'Building Sector'}, \n",
    "           title='(a) National, Monthly Average Accounting',\n",
    "           color='building_sector',\n",
    "           width=600, \n",
    "           height=600, \n",
    "           trendline='ols',\n",
    "           hover_data=['location','building_category','building_name','climate_zone'], \n",
    "           color_discrete_sequence=['red', 'blue'],\n",
    "           template='plotly_white') \\\n",
    ".update_xaxes(range=[0,20],  constrain='domain', zeroline=True, zerolinewidth=2, zerolinecolor='black') \\\n",
    ".update_yaxes(scaleanchor = \"x\", scaleratio = 1, range=[0,20], constrain='domain', zeroline=True, zerolinewidth=2, zerolinecolor='black') \\\n",
    ".add_shape(type=\"line\", x0=0, y0=0, x1=20, y1=20, line=dict(color=\"Black\", width=1)) \\\n",
    ".update_traces(marker=dict(opacity=0.35, size=4)) \\\n",
    ".add_annotation(x=15, y=15,\n",
    "                text=\"no change in bias\",\n",
    "                showarrow=False,\n",
    "                textangle=-45,\n",
    "                yshift=15) \\\n",
    ".add_annotation(x=7.5, y=15,\n",
    "                text=\"Monthly CI<br>increases bias\",\n",
    "                showarrow=False,\n",
    "                textangle=0,\n",
    "                yshift=0) \\\n",
    ".add_annotation(x=15, y=7.5,\n",
    "                text=\"Monthly CI<br>decreases bias\",\n",
    "                showarrow=False,\n",
    "                textangle=0,\n",
    "                yshift=0) \\\n",
    ".update_layout(font_family=\"Helvetica\", font_size=14, title=dict(yanchor=\"bottom\",xanchor='center',x=0.5, y=0.9), legend=dict(\n",
    "    yanchor=\"bottom\",\n",
    "    x=0.5,\n",
    "    y=0.98,\n",
    "    xanchor='center',\n",
    "    orientation='h'))\n",
    "\n",
    "annual_vs_monthly.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_vs_monthly.write_image(\"../results/figures/figure_4/national_annual_vs_monthly.svg\", scale=1.77165)\n",
    "annual_vs_monthly.write_image(\"../results/figures/figure_4/national_annual_vs_monthly.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_vs_monthlytod = px.scatter(percent_error_wide, \n",
    "           x=abs(percent_error_wide['annual']), \n",
    "           y=abs(percent_error_wide['monthhourly']), \n",
    "           labels={'x':'Absolute % Error (Annual)', 'y':'Absolute % Error (Monthly TOD)','building_sector':'Building Sector'}, \n",
    "           title='(c) National, Monthly TOD Average Accounting',\n",
    "           color='building_sector',\n",
    "           width=600, \n",
    "           height=600, \n",
    "           trendline='ols',\n",
    "           hover_data=['location','building_category','building_name','climate_zone'], \n",
    "           color_discrete_sequence=['red', 'blue'],\n",
    "           template='plotly_white') \\\n",
    ".update_xaxes(range=[0,20],  constrain='domain', zeroline=True, zerolinewidth=2, zerolinecolor='black') \\\n",
    ".update_yaxes(scaleanchor = \"x\", scaleratio = 1, range=[0,20], constrain='domain', zeroline=True, zerolinewidth=2, zerolinecolor='black') \\\n",
    ".add_shape(type=\"line\", x0=0, y0=0, x1=20, y1=20, line=dict(color=\"Black\", width=1)) \\\n",
    ".update_traces(marker=dict(opacity=0.35, size=4)) \\\n",
    ".add_annotation(x=15, y=15,\n",
    "                text=\"no change in bias\",\n",
    "                showarrow=False,\n",
    "                textangle=-45,\n",
    "                yshift=15) \\\n",
    ".add_annotation(x=7.5, y=15,\n",
    "                text=\"Monthly TOD CI<br>increases bias\",\n",
    "                showarrow=False,\n",
    "                textangle=0,\n",
    "                yshift=0) \\\n",
    ".add_annotation(x=15, y=7.5,\n",
    "                text=\"Monthly TOD CI<br>decreases bias\",\n",
    "                showarrow=False,\n",
    "                textangle=0,\n",
    "                yshift=0) \\\n",
    ".update_layout(font_family=\"Helvetica\", font_size=14, title=dict(yanchor=\"bottom\",xanchor='center',x=0.5, y=0.9), legend=dict(\n",
    "    yanchor=\"bottom\",\n",
    "    x=0.5,\n",
    "    y=0.98,\n",
    "    xanchor='center',\n",
    "    orientation='h'))\n",
    "\n",
    "annual_vs_monthlytod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_vs_monthlytod.write_image(\"../results/figures/figure_4/national_annual_vs_monthlytod.svg\", scale=1.77165)\n",
    "annual_vs_monthlytod.write_image(\"../results/figures/figure_4/national_annual_vs_monthlytod.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Results for DOPD and CHPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_percent_error = percent_error_outliers.copy()[percent_error_outliers['resolution'] == 'annual'].drop(columns=['resolution'])\n",
    "outlier_percent_error['building_sector'] = 'Commercial'\n",
    "outlier_percent_error.loc[outlier_percent_error['building_category'] == 'Residential', 'building_sector'] = 'Residential'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_bias_region_building = px.box(outlier_percent_error.replace({'location':ba_name_dict}), \n",
    "       x='building_category', \n",
    "       y='error', \n",
    "       facet_col='location', \n",
    "       facet_col_wrap=5, \n",
    "       facet_row_spacing=0.02, \n",
    "       category_orders={'location':sorted(ba_list)}, #sorted(ba_code_list)\n",
    "       template='plotly_white', \n",
    "       labels={'error':'Bias (%)','building_category':'Building Type'}, \n",
    "       #hover_data=['building_name','climate_zone'], \n",
    "       width=1200, \n",
    "       boxmode='overlay') \\\n",
    ".update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='black', dtick=20, rangemode='tozero', range=[-60,200]) \\\n",
    ".update_xaxes(tickangle=45, showgrid=True, ticklabelposition='outside top') \\\n",
    ".for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1])) \\\n",
    ".update_layout(boxgap=0.01) \\\n",
    ".update_layout(font_family=\"Helvetica\", font_size=14)\n",
    "\n",
    "outlier_bias_region_building.write_image(\"../results/figures/SI/outlier_bias_region_building.jpeg\")\n",
    "outlier_bias_region_building.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_error_by_region_sector = px.box(outlier_percent_error.replace({'location':ba_name_dict}), \n",
    "       x='location', \n",
    "       y='error', \n",
    "       category_orders={'location':[ba_name_dict[i] for i in descending_median_order]}, #sorted(ba_code_list)\n",
    "       template='plotly_white', \n",
    "       labels={'error':'%  by which annual EF...','location':'Balancing Authority','building_sector':'Building Sector'}, \n",
    "       hover_data=['building_name','climate_zone'], \n",
    "       color='building_sector',\n",
    "       #color_discrete_map={'day':'yellow','night':'navy', 'flat':'orange'},\n",
    "       width=300, \n",
    "       height=800,\n",
    "       boxmode='overlay') \\\n",
    ".update_yaxes(zeroline=True, zerolinewidth=2, zerolinecolor='black') \\\n",
    ".update_xaxes(tickangle=45, showgrid=True, ticks='outside') \\\n",
    ".update_layout(boxgap=0.01) \\\n",
    ".add_annotation(x=0, y=(outlier_percent_error['error'].max()/2),\n",
    "                text=\"...Overestimates GHG\",\n",
    "                showarrow=False,\n",
    "                textangle=-90,\n",
    "                xref='paper',\n",
    "                xshift=-45) \\\n",
    ".add_annotation(x=0, y=-6,\n",
    "                text=\"...Underestimates GHG\",\n",
    "                showarrow=False,\n",
    "                textangle=-90,\n",
    "                xref='paper',\n",
    "                xshift=-45) \\\n",
    ".update_layout(legend=dict(\n",
    "    yanchor=\"top\",\n",
    "    x=0.5,\n",
    "    y=1.07,\n",
    "    xanchor='center',\n",
    "    orientation='h')) \\\n",
    ".update_layout(font_family=\"Helvetica\", font_size=14)\n",
    "\n",
    "outlier_error_by_region_sector.write_image(\"../results/figures/SI/outlier_error_by_region_sector.jpeg\")\n",
    "outlier_error_by_region_sector.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_efs = ef.copy()[['DOPD','CHPD']].xs('hourly',axis=1,level=1,drop_level=True)\n",
    "outlier_efs = outlier_efs * unit_conversion\n",
    "outlier_efs = outlier_efs.melt(var_name='region', ignore_index=False).reset_index()\n",
    "outlier_efs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_ef = px.line(outlier_efs.replace({'region':ba_name_dict}), \n",
    "        x='datetime_local',\n",
    "        y='value',\n",
    "        facet_col='region',\n",
    "        facet_col_wrap=1,\n",
    "        template='plotly_white', \n",
    "        labels={'value':'lbCO2/MWh', 'datetime_local':'Datetime'},\n",
    "        width=1200) \\\n",
    ".update_xaxes(dtick='M1', tickformat='%b') \\\n",
    ".for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1])) \\\n",
    ".update_layout(font_family=\"Helvetica\", font_size=14)\n",
    "\n",
    "outlier_ef.write_image(\"../results/figures/SI/outlier_ef.jpeg\")\n",
    "outlier_ef.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Building Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demand_region = 'ISNE'\n",
    "demand_viz = demand.loc[:, (demand_region, slice(None))].droplevel(axis=1, level=0)\n",
    "# normalize demand profiles\n",
    "demand_viz = demand_viz / demand_viz.max(axis=0)\n",
    "demand_viz['datetime'] = pd.date_range(start='2018-01-01 00:00:00', end='2018-12-31 23:00:00', freq='H')\n",
    "demand_viz = demand_viz.groupby([demand_viz.datetime.dt.month, demand_viz.datetime.dt.hour]).mean()\n",
    "demand_viz.index = demand_viz.index.set_names(['month','hour'])\n",
    "demand_viz = demand_viz.reset_index().melt(id_vars=['month','hour'],var_name='building', value_name='demand')\n",
    "# create new columns\n",
    "demand_viz['climate_zone'] = demand_viz['building'].str.split('_', expand=True)[0]\n",
    "demand_viz['building_category'] = demand_viz['building'].str.split('_', expand=True)[1]\n",
    "demand_viz['building_name'] = demand_viz['building'].str.split('_', expand=True)[2]\n",
    "demand_viz['building_id'] = demand_viz['building'].str.split('_', expand=True)[3]\n",
    "\n",
    "demand_viz['building_sector'] = 'Commercial'\n",
    "residential_buildings = ['MobileHome', 'SingleFamily', 'MediumMultifamily',\n",
    "       'SmallMultifamily', 'LargeMultifamily']\n",
    "demand_viz.loc[demand_viz['building_category'].isin(residential_buildings), 'building_sector'] = 'Residential'\n",
    "demand_viz = demand_viz.groupby(['building_sector','building_category','month','hour']).mean().reset_index()\n",
    "demand_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "com_demand = px.line(demand_viz[demand_viz['building_sector'] == 'Commercial'], x='hour', y='demand', facet_col='month', facet_col_wrap=3, color='building_category', height=1000, width=800, template='plotly_white', title=f'Average normalized demand profiles for commercial buildings in {demand_region}').update_yaxes(range=[0,1]).update_xaxes(dtick=3)\n",
    "com_demand.write_image(f\"../results/figures/SI/com_demand_profiles_{demand_region}.jpeg\")\n",
    "com_demand.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_demand = px.line(demand_viz[demand_viz['building_sector'] == 'Residential'], x='hour', y='demand', facet_col='month', facet_col_wrap=3, color='building_category', height=1000, width=800, template='plotly_white', title=f'Average normalized demand profiles for residential buildings in {demand_region}').update_yaxes(range=[0,1]).update_xaxes(dtick=3)\n",
    "res_demand.write_image(f\"../results/figures/SI/res_demand_profiles_{demand_region}.jpeg\")\n",
    "res_demand.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Bias Mathematically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_code_list = ['IID']\n",
    "\n",
    "# calculate residual between average EF and actual hourly EF\n",
    "residual = ef.copy()\n",
    "for ba in ba_code_list:\n",
    "    for res in ['annual','monthly','monthhourly','hourly']:\n",
    "        residual[ba][res] = residual.copy()[ba][res] - ef.copy()[ba]['hourly']\n",
    "\n",
    "# format the percent error data\n",
    "pe_formatted = percent_error_wide.copy()\n",
    "pe_formatted['building_type'] = pe_formatted[['building_category','building_name','climate_zone']].agg('_'.join, axis=1)\n",
    "pe_formatted = pe_formatted.set_index(['location','building_type']).drop(columns=['building_category','building_name','climate_zone'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = pd.DataFrame(columns=['ef_resolution'])\n",
    "\n",
    "for ba in ba_code_list: #list(percent_error.location.unique()):\n",
    "    for frequency in ['annual', 'monthly','monthhourly']:\n",
    "        bias_i = pd.DataFrame(columns=['ef_resolution'])\n",
    "        bias_i['E[D]'] = demand[ba].mean()\n",
    "        bias_i['E[u]'] = residual[ba][frequency].mean()\n",
    "        bias_i['stdev_D'] = demand[ba].std(ddof=0)\n",
    "        bias_i['stdev_u'] = residual[ba][frequency].std(ddof=0)\n",
    "        bias_i['corr(D,u)'] = demand[ba].corrwith(residual[ba][frequency])\n",
    "        bias_i['E[D]*E[u]'] = bias_i['E[D]'] * bias_i['E[u]']\n",
    "        bias_i['std_D*std_D*corr(D,u)'] = (bias_i['stdev_D'] * bias_i['stdev_u'] * bias_i['corr(D,u)'])\n",
    "        bias_i['E[D*u]'] = bias_i['E[D]*E[u]'] + bias_i['std_D*std_D*corr(D,u)']\n",
    "        bias_i['E[C]'] = demand[ba].mul(ef[ba]['hourly'], axis=0).mean()\n",
    "        bias_i['stdev_C'] = demand[ba].mul(ef[ba]['hourly'], axis=0).std(ddof=0)\n",
    "        bias_i['E[D*u] / E[C]'] = (bias_i['E[D*u]'] / bias_i['E[C]'])\n",
    "        bias_i['percent_error'] = pe_formatted.loc[(ba, slice(None)), frequency].droplevel('location')\n",
    "        bias_i['ef_resolution'] = frequency\n",
    "        bias_i['BA'] = ba\n",
    "\n",
    "        bias_i = bias_i.reset_index()\n",
    "\n",
    "        bias = bias.append(bias_i, ignore_index=True)\n",
    "\n",
    "bias = bias.round(3)\n",
    "bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias[(bias['BA']=='ISNE') & (bias['building_type'].str.contains('Residential')) & (bias['ef_resolution'].isin(['annual','monthly']))].sort_values(by=['building_type','ef_resolution'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias[(bias['BA']=='AZPS') & (bias['building_type'].isin(['Residential_SmallSingleFamily_2B'])) & (bias['ef_resolution'].isin(['annual','monthly']))].sort_values(by=['building_type','ef_resolution'])[['ef_resolution','stdev_D','stdev_u','corr(D,u)','E[D*u]','percent_error']] #'Residential_LargeSingleFamily_3B','Residential_SmallSingleFamily_2B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(bias, x=(bias['stdev_D'] / bias['E[D]']), y='percent_error', labels={'x':'COV of demand', 'percent_error':'Bias (% error)'}, title='Effect of building demand variance on inventory bias').update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(bias, x=(bias['stdev_C'] / bias['E[C]']), y='percent_error', labels={'x':'COV of errors in emission estimates', 'percent_error':'Bias (% error)'}, title='Effect of carbon intensity error variance on inventory bias', hover_data=['BA','building_type','ef_resolution']).update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='black')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bbfb11d76ba7fcd62de728492717c2999a3c11ae1c83ea329d6e038c7a5b35c0"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('emissions': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
