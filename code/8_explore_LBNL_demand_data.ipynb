{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from pathlib import Path\n",
    "import plotly.express as px\n",
    "import plotly\n",
    "from os import path\n",
    "import missingno\n",
    "import re\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "\n",
    "# import project modules\n",
    "import download_data\n",
    "import screening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For California, the is a source of facility-level hourly demand data, based on actual AMI readings. \n",
    " - LBNL 2025 California Demand Response Potential Study, Phase 2 (https://www.cpuc.ca.gov/General.aspx?id=10622). As part of this project AMI data was collected from the three major IOUs and the aggregated/anonymized data are available for download (https://buildings.lbl.gov/download-page-2025-california-demand-response)\n",
    "\n",
    "This dataset is useful for two main purposes:  \n",
    "1. Provide a source of demand data for facility types not included in the DOE dataset (e.g. data centers)  \n",
    "2. These data can be used to help validate that the DOE simulations are reasonably accurate.\n",
    "\n",
    "### Description of building type codes\n",
    "- retail\n",
    "- office\n",
    "- refrigerated warehouse\n",
    "- other\n",
    "- Petroleum Refining and Related Industries \n",
    "- Food Manufacturing, Beverage and Tobacco \n",
    "- Chemicals - Industrial Gases \n",
    "- Chemicals - Other \n",
    "- Computer and Electronic Product Manufacturing \n",
    "- Plastics and Rubber Products Manufacturing \n",
    "- Primary Metals \n",
    "- Agriculture - crops: irrigation pumping primarily\n",
    "- Water\n",
    "- Wastewater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's explore the metadata\n",
    "metadata = pd.read_csv('A:/Research/lbnl-load-enduse-shapes/lbnl-load-enduse-shapes/anonymized_1in2_actual_actual_2014/anonymized_1in2_actual_actual_2014_cluster_summary.csv')\n",
    "\n",
    "metadata.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[['customer_count','util','slap','sector','building_type']].groupby(['util','building_type']).count().reset_index().pivot(index='util', columns='building_type', values='customer_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[['customer_count','util','slap','sector','building_type']].groupby(['slap','building_type']).count().reset_index().pivot(index='slap', columns='building_type', values='customer_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata[['customer_count','util','slap','sector','building_type','kw_bin']].groupby(['kw_bin','building_type']).count().reset_index().pivot(index='building_type', columns='kw_bin', values='customer_count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating load shapes\n",
    "\n",
    "To aggregate the data I have a couple of options:  \n",
    "1. sum together all of the load of a certain building type and use that load shape. However, this weights large facilities more\n",
    "2. Average together normalized load shapes from each bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters\n",
    "util = ['pge']\n",
    "slap = None\n",
    "sector = None\n",
    "building_type = ['office']\n",
    "care = ['nonCare']\n",
    "kw_bin = None\n",
    "\n",
    "filename_list = metadata.copy()\n",
    "\n",
    "if util is not None:\n",
    "    filename_list = filename_list[filename_list['util'].isin(util)]\n",
    "if slap is not None:\n",
    "    filename_list = filename_list[filename_list['slap'].isin(slap)]\n",
    "if sector is not None:\n",
    "    filename_list = filename_list[filename_list['sector'].isin(sector)]\n",
    "if building_type is not None:\n",
    "    filename_list = filename_list[filename_list['building_type'].isin(building_type)]\n",
    "if care is not None:\n",
    "    filename_list = filename_list[filename_list['care'].isin(care)]\n",
    "if kw_bin is not None:\n",
    "    filename_list = filename_list[filename_list['kw_bin'].isin(kw_bin)]\n",
    "\n",
    "\n",
    "filename_list = list(filename_list['cluster'])\n",
    "\n",
    "len(filename_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use 1-in-2 profiles, representing a typical weather year, rather than the 1-in-10 profiles, which represent a \"hot\" year\n",
    "lbnl_dir = 'A:/Research/lbnl-load-enduse-shapes/lbnl-load-enduse-shapes/anonymized_1in2_actual_actual_2014/'\n",
    "\n",
    "#file_format = f'{utility}-{sector}-{sublap}-{building_type}-{kw_bin}-{care}-{kwh_bin}.csv'\n",
    "\n",
    "\n",
    "data = pd.DataFrame()\n",
    "for filename in filename_list:\n",
    "    # let's take a look a single building type with different kwh bins\n",
    "    df = pd.read_csv(lbnl_dir + f'{filename}.csv', usecols=['total']).rename(columns={'total':filename})\n",
    "\n",
    "    data = data.join(df, how='right')\n",
    "\n",
    "# add an index\n",
    "data.index = pd.date_range(start='2014-01-01 00:00:00', end='2014-12-31 23:00:00', freq='H')\n",
    "\n",
    "# normalize the data\n",
    "\"\"\"\n",
    "for col in data.columns:\n",
    "\n",
    "    data[col] = data[col] / data[col].max()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.std(ddof=0) / data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.box(data.std(ddof=0) / data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot1 = px.line(data, width=1000)\n",
    "plot1.update_xaxes(\n",
    "    #rangeslider_visible=True,\n",
    "    rangeselector=dict(\n",
    "        buttons=list([\n",
    "            dict(count=1, label=\"1d\", step=\"day\", stepmode=\"backward\"),\n",
    "            dict(count=7, label=\"1w\", step=\"day\", stepmode=\"backward\"),\n",
    "            dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(step=\"all\")\n",
    "        ])))\n",
    "plot1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert the data to tslearn format\n",
    "ts_data = data.to_numpy().T\n",
    "\n",
    "# set the number of clusters as the square root of the number of profiles\n",
    "cluster_count = math.ceil(math.sqrt(len(ts_data))) \n",
    "\n",
    "# cluster the data using k-means with euclinean distance\n",
    "km = TimeSeriesKMeans(n_clusters=cluster_count)\n",
    "clusters = km.fit_predict(ts_data)\n",
    "\n",
    "# assign each building to a cluster\n",
    "cluster_dict = {list(data.columns)[i]: list(clusters)[i] for  i in range(len(data.columns))}\n",
    "\n",
    "# format the data for plotting\n",
    "cluster_plot_data = data.reset_index().melt(id_vars='index',var_name='building', value_name='normalized_demand')\n",
    "cluster_plot_data['cluster'] = cluster_plot_data['building'].map(cluster_dict)\n",
    "\n",
    "cluster_plot_data = cluster_plot_data.groupby(['cluster','index']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(cluster_plot_data, x='index', y='normalized_demand', facet_col='cluster', width=1200, height=800, facet_col_wrap=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name =  'sce-ind-SCEW-data_center-50_200kW-nonCare-0.0_1.0'\n",
    "\n",
    "mh = data[[col_name]].groupby([data.index.month, data.index.hour]).mean()\n",
    "mh.index = mh.index.set_names(['month','hour'])\n",
    "px.line(mh.reset_index(), x='hour', y=col_name, facet_col='month').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_use = data.groupby(data.index.month).mean()\n",
    "monthly_use.index = monthly_use.index.rename('month')\n",
    "monthly_use = monthly_use.reset_index().melt(id_vars='month', var_name='building',value_name='normalized_demand')\n",
    "\n",
    "px.bar(monthly_use, x='month', y='normalized_demand', facet_col='building', facet_col_wrap=5, height=800, width=1200).for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1])).update_yaxes(range=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_use = data.groupby(data.index.dayofweek).mean()\n",
    "weekly_use.index = weekly_use.index.rename('day_of_week')\n",
    "weekly_use = weekly_use.reset_index().melt(id_vars='day_of_week', var_name='building',value_name='normalized_demand')\n",
    "\n",
    "px.bar(weekly_use, x='day_of_week', y='normalized_demand', facet_col='building', facet_col_wrap=5, height=500, width=800).for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1])).update_yaxes(range=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_use = data.groupby(data.index.hour).mean()\n",
    "daily_use.index = daily_use.index.rename('hour')\n",
    "daily_use = daily_use.reset_index().melt(id_vars='hour', var_name='building',value_name='normalized_demand')\n",
    "\n",
    "px.bar(daily_use, x='hour', y='normalized_demand', facet_col='building', facet_col_wrap=5, height=500, width=800).for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1])).update_yaxes(range=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Profiles of interest\n",
    "\n",
    "- Food/Bev:\n",
    "    - 'pge-ind-PGSA-food_bev-gt200kW-nonCare-0.0_0.33' - spike from Aug 11 to Sept 11\n",
    "    - 'pge-ind-PGSA-food_bev-gt200kW-nonCare-0.66_1.0' - spike from July - September\n",
    "    - 'sce-ind-SCEW-food_bev-gt200kW-nonCare-0.1_0.2' - spike for 2-3 weeks late september, but same overnight baseline use\n",
    "- Data Center\n",
    "    - 'pge-ind-PGSB-data_center-gt200kW-nonCare-0.0_1.0' - daily and day of week seasonality, but almost no annual seasonality\n",
    "- Metals\n",
    "    - 'sdge-ind-SDG1-metals-50_200kW-nonCare-0.0_0.25' - almost no annual seasonality, strong day/night swing with almost zero overnight use\n",
    "- Refrigerated Warehouses - tend to have strong seasonal and daily load, correlated with solar\n",
    "    - 'pge-com-PGF1-ref_wh-lt50kW-nonCare-0.0_1.0' - seems to use most energy in evening and overnight\n",
    "    - 'sce-com-PGLP-com_other-noKW-nonCare-0.0_1.0' - shows strong midday peak correlating with solar, as well as seasonal pea kin summer\n",
    "- Water\n",
    "    - 'sce-ind-SCEW-water-gt200kW-nonCare-0.1_0.2' - very little variation within a tight band\n",
    "- Crop\n",
    "    - 'sdge-ind-SDG1-crop-lt50kW-nonCare-0.5_0.6' - strong overnight pumping pattern\n",
    "- Chemical Manufacturing\n",
    "    - 'sce-ind-SCEN-chemical-50_200kW-nonCare-0.0_1.0' - night shift work, almost zero energy use during day, no annual or DOW seasonality\n",
    "    - 'sce-ind-SCEC-chemical-50_200kW-nonCare-0.0_1.0' - strong day shift with annual seasonality and almost 0 use over weekend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Profiles of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_files = ['pge-ind-PGSA-food_bev-gt200kW-nonCare-0.0_0.33',\n",
    "                     'pge-ind-PGSA-food_bev-gt200kW-nonCare-0.66_1.0',\n",
    "                     'pge-ind-PGSB-data_center-gt200kW-nonCare-0.0_1.0',\n",
    "                     'sdge-ind-SDG1-metals-50_200kW-nonCare-0.0_0.25',\n",
    "                     'pge-com-PGF1-ref_wh-lt50kW-nonCare-0.0_1.0',\n",
    "                     'sce-com-PGLP-com_other-noKW-nonCare-0.0_1.0',\n",
    "                     'sce-ind-SCEW-water-gt200kW-nonCare-0.1_0.2',\n",
    "                     'sdge-ind-SDG1-crop-lt50kW-nonCare-0.5_0.6',\n",
    "                     'sce-ind-SCEN-chemical-50_200kW-nonCare-0.0_1.0',\n",
    "                     'sce-ind-SCEC-chemical-50_200kW-nonCare-0.0_1.0'\n",
    "                     ]\n",
    "\n",
    "building_names = {'pge-ind-PGSA-food_bev-gt200kW-nonCare-0.0_0.33':'ag_tree_nut_processor',\n",
    "                        'pge-ind-PGSA-food_bev-gt200kW-nonCare-0.66_1.0':'ag_tomato_processor',\n",
    "                        'sce-ind-SCEW-food_bev-gt200kW-nonCare-0.1_0.2':'ag_prune_processor',\n",
    "                        'pge-ind-PGSB-data_center-gt200kW-nonCare-0.0_1.0':'data_center',\n",
    "                        'sdge-ind-SDG1-metals-50_200kW-nonCare-0.0_0.25':'metals_day_shift',\n",
    "                        'pge-com-PGF1-ref_wh-lt50kW-nonCare-0.0_1.0':'warehouse_overnight',\n",
    "                        'sce-com-PGLP-com_other-noKW-nonCare-0.0_1.0':'warehouse_midday',\n",
    "                        'sce-ind-SCEW-water-gt200kW-nonCare-0.1_0.2':'water_constant_load',\n",
    "                        'sdge-ind-SDG1-crop-lt50kW-nonCare-0.5_0.6':'crop_overnight_pumping',\n",
    "                        'sce-ind-SCEN-chemical-50_200kW-nonCare-0.0_1.0':'chem_night_shift',\n",
    "                        'sce-ind-SCEC-chemical-50_200kW-nonCare-0.0_1.0':'chem_day_shift'\n",
    "                        }\n",
    "\n",
    "# we will use 1-in-2 profiles, representing a typical weather year, rather than the 1-in-10 profiles, which represent a \"hot\" year\n",
    "lbnl_dir = 'A:/Research/lbnl-load-enduse-shapes/lbnl-load-enduse-shapes/anonymized_1in2_actual_actual_2014/'\n",
    "\n",
    "#file_format = f'{utility}-{sector}-{sublap}-{building_type}-{kw_bin}-{care}-{kwh_bin}.csv'\n",
    "\n",
    "\n",
    "interesting = pd.DataFrame()\n",
    "for filename in interesting_files:\n",
    "    # let's take a look a single building type with different kwh bins\n",
    "    df = pd.read_csv(lbnl_dir + f'{filename}.csv', usecols=['total']).rename(columns={'total':filename})\n",
    "\n",
    "    interesting = interesting.join(df, how='right')\n",
    "\n",
    "# add an index\n",
    "interesting.index = pd.date_range(start='2014-01-01 00:00:00', end='2014-12-31 23:00:00', freq='H')\n",
    "\n",
    "# normalize the interesting\n",
    "for col in interesting.columns:\n",
    "\n",
    "    interesting[col] = interesting[col] / interesting[col].max()\n",
    "\n",
    "interesting = interesting.rename(columns=building_names)\n",
    "\n",
    "plot2 = px.line(interesting, width=1000)\n",
    "plot2.update_xaxes(\n",
    "    #rangeslider_visible=True,\n",
    "    rangeselector=dict(\n",
    "        buttons=list([\n",
    "            dict(count=1, label=\"1d\", step=\"day\", stepmode=\"backward\"),\n",
    "            dict(count=7, label=\"1w\", step=\"day\", stepmode=\"backward\"),\n",
    "            dict(count=1, label=\"1m\", step=\"month\", stepmode=\"backward\"),\n",
    "            dict(step=\"all\")\n",
    "        ])))\n",
    "plot2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_use = interesting.groupby(interesting.index.month).mean()\n",
    "monthly_use.index = monthly_use.index.rename('month')\n",
    "monthly_use = monthly_use.reset_index().melt(id_vars='month', var_name='building',value_name='normalized_demand')\n",
    "\n",
    "px.bar(monthly_use, x='month', y='normalized_demand', facet_col='building', facet_col_wrap=5, height=500, width=800).for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1])).update_yaxes(range=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_use = interesting.groupby(interesting.index.dayofweek).mean()\n",
    "weekly_use.index = weekly_use.index.rename('day_of_week')\n",
    "weekly_use = weekly_use.reset_index().melt(id_vars='day_of_week', var_name='building',value_name='normalized_demand')\n",
    "\n",
    "px.bar(weekly_use, x='day_of_week', y='normalized_demand', facet_col='building', facet_col_wrap=5, height=500, width=800).for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1])).update_yaxes(range=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_use = interesting.groupby(interesting.index.hour).mean()\n",
    "daily_use.index = daily_use.index.rename('hour')\n",
    "daily_use = daily_use.reset_index().melt(id_vars='hour', var_name='building',value_name='normalized_demand')\n",
    "\n",
    "px.bar(daily_use, x='hour', y='normalized_demand', facet_col='building', facet_col_wrap=5, height=500, width=800).for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1])).update_yaxes(range=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seasonal Fixed Effects Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loop through possible combinations\n",
    "\n",
    "combinations = ['C(year):C(month):C(dayofweek):C(hour)',\n",
    "    'C(year):C(month):C(hour)',\n",
    "    'C(year):C(month)',\n",
    "    'C(year)'\n",
    "]\n",
    "\n",
    "r2 = pd.DataFrame(index=pd.MultiIndex(levels=[[],[]], codes=[[],[]], names=['building','fixed_effect']))\n",
    "\n",
    "for building in interesting.columns:\n",
    "    data = interesting.copy()[[building]]\n",
    "\n",
    "    # create new columns for different seasonalities\n",
    "    data['year'] = data.index.year\n",
    "    data['month'] = data.index.month\n",
    "    data['dayofweek'] = data.index.dayofweek\n",
    "    data['hour'] = data.index.hour\n",
    "\n",
    "    # for each combination of regressors, run a linear model and store the results\n",
    "    for combination in combinations:\n",
    "        # only keep the regressors that we care about\n",
    "        #X = data_dummy[[col for col in data_dummy if any(effect in col for effect in combination)]]\n",
    "        #X = sm.add_constant(X)\n",
    "\n",
    "        # fit the model, dropping any missing values\n",
    "        model = ols(f'{building} ~ ' + combination, data=data).fit()\n",
    "        #predictions = model.predict(X)\n",
    "\n",
    "        # save the Rsquared value\n",
    "        r2.loc[(building, str(combination)),'r2'] = model.rsquared\n",
    "        r2.loc[(building, str(combination)),'adj_r2'] = model.rsquared_adj\n",
    "\n",
    "# reverse the order of the columns\n",
    "r2 = r2.iloc[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2.to_csv('../results/lbnl_r2_values.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reformat labels\n",
    "relabels = {'C(year):C(month):C(dayofweek):C(hour)':'year:month:dayofweek:hour',\n",
    "    'C(year):C(month):C(hour)':'year:month:hour',\n",
    "    'C(year):C(month)':'year:month',\n",
    "    'C(year)':'year'\n",
    "    }\n",
    "\n",
    "\n",
    "px.scatter(r2.sort_index(level='building', sort_remaining=False).reset_index().replace(relabels), x='fixed_effect', y='r2', color='r2', facet_col='building', title='R-squared values',template='plotly_white', width=1200, height=600, facet_col_wrap=6, color_continuous_scale='Portland_r').update_yaxes(range=[0,1], dtick=0.1).for_each_annotation(lambda a: a.update(text=a.text.split(\"=\")[-1])).add_hline(y=0.5, line_dash='dot').add_hline(y=1).add_hline(y=0).update_coloraxes(cmin=0, cmax=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('emissions': conda)",
   "name": "python3710jvsc74a57bd0bbfb11d76ba7fcd62de728492717c2999a3c11ae1c83ea329d6e038c7a5b35c0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
